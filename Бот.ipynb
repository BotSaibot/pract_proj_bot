{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvJtPJn58cY+eRXdeOja2A"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Практический проект \"Бот\""
      ],
      "metadata": {
        "id": "LFbiUQVTvD3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Туториал](https://habr.com/ru/articles/732136/)"
      ],
      "metadata": {
        "id": "y9BwKfvKx9np"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13gchAUPu8SB"
      },
      "outputs": [],
      "source": [
        "'''Парсер (веб-скрапер) объявлений с HeadHunter.'''\n",
        "import requests\n",
        "import bs4\n",
        "\n",
        "\n",
        "RESOURCE_URL = 'https://hh.ru/search/vacancy'\n",
        "RESOURCE_HEADER = {'user-agent': 'py-parser/2.3'}\n",
        "\n",
        "\n",
        "def get_response(**kwargs) -> bs4.BeautifulSoup:\n",
        "    '''Возвращает проанализированный HTML-документ ответа от ресурса по URL\n",
        "    адресу.'''\n",
        "    response = requests.get(**kwargs, timeout=4)\n",
        "    response.raise_for_status()\n",
        "    check = 'text/html' in response.headers.get('Content-Type')\n",
        "    assert check, 'Response has the wrong content-type!'\n",
        "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "\n",
        "def tree_traversal(doc: bs4.BeautifulSoup, params: dict) -> dict:\n",
        "    '''Рекурсивный обход дерева полного графа, возвращает словарь.\n",
        "    Т.е. здесь извлекаем из HTML-документа только полезную информацию.'''\n",
        "    out = {}\n",
        "    index = 0\n",
        "\n",
        "    host_url = requests.urllib3.get_host(\n",
        "        doc.find('link', {'rel': 'canonical'})['href']\n",
        "    )\n",
        "\n",
        "    total_pages = int(\n",
        "        doc.find('h1',\n",
        "                 {'class': 'bloko-header-section-3'}).getText().split()[0]\n",
        "    )\n",
        "    total_pages = (total_pages // params['items_on_page']\n",
        "                   + (total_pages % params['items_on_page'] > 0))\n",
        "\n",
        "    for page_num in range(total_pages):\n",
        "\n",
        "        if page_num != 0:\n",
        "            params.update([('page', page_num),\n",
        "                           ('hhtmFrom', 'vacancy_search_list')])\n",
        "            doc = get_response(\n",
        "                url=RESOURCE_URL,\n",
        "                headers=RESOURCE_HEADER,\n",
        "                params=params\n",
        "            )\n",
        "\n",
        "        for item in doc.find_all('div', {'class': 'serp-item'}):\n",
        "\n",
        "            index += 1\n",
        "            vacancy_response = item.find(\n",
        "                'a', {'data-qa': 'vacancy-serp__vacancy_response'}\n",
        "                )\n",
        "\n",
        "            name = item.find('a', {'class': 'serp-item__title'})\n",
        "            key = bs4.re.search(r'[0-9]+', name['href'])[0]\n",
        "            name = name.getText() + (' [ARCHIVED]'\n",
        "                                     if vacancy_response is None else '')\n",
        "\n",
        "            area = item.find(\n",
        "                'div', {'data-qa': 'vacancy-serp__vacancy-address'}\n",
        "                ).getText()\n",
        "\n",
        "            salary = item.find(\n",
        "                'span', {'data-qa': 'vacancy-serp__vacancy-compensation'})\n",
        "            if salary is not None:\n",
        "                salary = salary.getText().replace('\\u202f', '')\n",
        "\n",
        "            url = host_url[0] + '://' + host_url[1] + '/vacancy/' + key\n",
        "            employer = item.find(\n",
        "                'a', {'data-qa': 'vacancy-serp__vacancy-employer'})\n",
        "            if employer is not None:\n",
        "                employer = employer.getText().replace('\\xa0', ' ')\n",
        "            else:\n",
        "                employer = item.find(\n",
        "                    'div', {'class': 'vacancy-serp-item__meta-info-company'}\n",
        "                    ).getText().replace('\\xa0', ' ')\n",
        "\n",
        "            out[index] = {'key': key, 'name': name, 'area': area,\n",
        "                          'salary': salary, 'url': url, 'employer': employer}\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def data_to_file(data: dict, f_name: str) -> None:\n",
        "    '''Записывает словарь в файл в кодировке UTF-8.'''\n",
        "    with open(f_name, 'w', encoding='utf-8') as fout:\n",
        "\n",
        "        for index, value in data.items():\n",
        "            key, name, area, salary, url, employer = value.values()\n",
        "\n",
        "            out = (f'''{index} {key} {url}\\n\\t{name}\\n\\t'''\n",
        "                   f'''\"{employer}\", {area}\\n\\t{salary}\\n\\n''')\n",
        "\n",
        "            fout.write(out)\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    '''Главная функция.'''\n",
        "    params = {\n",
        "        'text': 'python',\n",
        "        'part_time': 'temporary_job_true',\n",
        "        'professional_role': 96,\n",
        "        'search_field': ['name', 'company_name', 'description'],\n",
        "        'enable_snippets': False,\n",
        "        'salary': 270_000,\n",
        "        'items_on_page': 20,\n",
        "        'only_with_salary': True,\n",
        "        'ored_clusters': True,\n",
        "        'order_by': 'publication_time',\n",
        "        'status': 'non_archived'\n",
        "    }\n",
        "\n",
        "    response = get_response(\n",
        "        url=RESOURCE_URL,\n",
        "        headers=RESOURCE_HEADER,\n",
        "        params=params\n",
        "        )\n",
        "\n",
        "    response = tree_traversal(response, params)\n",
        "    data_to_file(response, '/content/output.txt')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}